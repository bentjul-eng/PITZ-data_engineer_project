# ğŸ›’ Projeto ETL - Plataforma de E-commerce

Pipeline de dados moderno usando arquitetura **Medallion (Bronze, Silver, Gold)** para transformar dados operacionais em insights de negÃ³cio.

---

## ğŸ“‹ Ãndice

- [VisÃ£o Geral](#-visÃ£o-geral)
- [Arquitetura](#-arquitetura)
- [Tecnologias](#-tecnologias)
- [PrÃ©-requisitos](#-prÃ©-requisitos)
- [InstalaÃ§Ã£o](#-instalaÃ§Ã£o)
- [Estrutura do Projeto](#-estrutura-do-projeto)
- [Como Executar](#-como-executar)
- [Camadas de Dados](#-camadas-de-dados)
- [Modelo de Dados](#-modelo-de-dados)
- [Consultas SQL](#-consultas-sql)
- [DecisÃµes TÃ©cnicas](#-decisÃµes-tÃ©cnicas)
- [Logs e Monitoramento](#-logs-e-monitoramento)
- [Troubleshooting](#-troubleshooting)

---

## ğŸ¯ VisÃ£o Geral

Este projeto implementa um pipeline ETL completo que:
- âœ… Extrai dados de mÃºltiplas fontes JSON
- âœ… Limpa e normaliza os dados seguindo padrÃµes de qualidade
- âœ… Modela dados em um Data Warehouse PostgreSQL
- âœ… ExpÃµe valor atravÃ©s de consultas SQL analÃ­ticas
- âœ… Pode ser executado mÃºltiplas vezes sem duplicaÃ§Ã£o (idempotente)

---

## ğŸ—ï¸ Arquitetura

Arquitetura Medallion**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FONTES DE DADOS (JSON)                   â”‚
â”‚  customers | transactions | reviews | tickets | inventory   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    BRONZE LAYER (Raw)                       â”‚
â”‚  â€¢ IngestÃ£o sem transformaÃ§Ã£o                               â”‚
â”‚  â€¢ Formato: Parquet                                         â”‚
â”‚  â€¢ Versionamento por timestamp                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   SILVER LAYER (Cleaned)                    â”‚
â”‚  â€¢ Limpeza e normalizaÃ§Ã£o                                   â”‚
â”‚  â€¢ ValidaÃ§Ã£o de qualidade                                   â”‚
â”‚  â€¢ DeduplicaÃ§Ã£o                                             â”‚
â”‚  â€¢ Formato: Parquet                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              GOLD LAYER (Business/Analytics)                â”‚
â”‚  â€¢ Modelo dimensional (PostgreSQL)                          â”‚
â”‚  â€¢ Tabelas: customers, orders                               â”‚
â”‚  â€¢ Relacionamentos (FK/PK)                                  â”‚
â”‚  â€¢ Pronto para consumo analÃ­tico                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ğŸ“Š CONSULTAS SQL                         â”‚
â”‚  â€¢ Total de vendas por cliente                              â”‚
â”‚  â€¢ NÃºmero de pedidos por paÃ­s                               â”‚
â”‚  â€¢ Ticket mÃ©dio                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

##  Tecnologias

| Categoria | Tecnologia | VersÃ£o | Justificativa |
|-----------|-----------|--------|---------------|
| **Linguagem** | Python | 3.8+ | PadrÃ£o da indÃºstria para Data Engineering |
| **Banco de Dados** | PostgreSQL | 15 | RDBMS robusto, open-source |
| **ContainerizaÃ§Ã£o** | Docker | - | Ambiente isolado e reproduzÃ­vel |
| **ManipulaÃ§Ã£o de Dados** | Pandas | 2.1+ | Biblioteca lÃ­der para transformaÃ§Ã£o de dados |
| **ORM/ConexÃ£o** | SQLAlchemy | 2.0+ | AbstraÃ§Ã£o robusta para banco de dados |
| **Formato IntermediÃ¡rio** | Parquet | - | Formato colunar eficiente |
| **Logs** | Python logging | - | Rastreabilidade e debugging |

---

## ğŸ“¦ PrÃ©-requisitos

### Software necessÃ¡rio:

- **Docker & Docker Compose** (recomendado)
  - [InstalaÃ§Ã£o Docker Desktop](https://www.docker.com/products/docker-desktop/)
  
- **Python 3.8+**
  ```bash
  python --version
  ```

- **pip** (gerenciador de pacotes Python)
  ```bash
  pip --version
  ```

### Opcional:
- **Git** (para clonar o repositÃ³rio)
---

## ğŸš€ InstalaÃ§Ã£o

### 1. Clonar o repositÃ³rio (ou baixar os arquivos)

```bash
git clone <url-do-repositorio>
cd PITZ-data_engineer_project
```

### 2. Configurar ambiente Python

```bash
# Criar ambiente virtual (recomendado)
python -m venv venv

# Ativar ambiente virtual
# Windows:
venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate

# Instalar dependÃªncias
pip install -r requirements.txt
```

### 3. Configurar PostgreSQL com Docker

```bash
# Subir o container PostgreSQL
docker compose up -d

# Verificar se estÃ¡ rodando
docker ps
```

### 4. Verificar arquivo .env

O arquivo `.env` deve conter:
```env
DB_HOST=localhost
DB_PORT=5432
DB_NAME=ecommerce
DB_USER=postgres
DB_PASSWORD=postgres
```

---

## ğŸ“ Estrutura do Projeto

```
PITZ-data_engineer_project/
â”‚
â”œâ”€â”€ .env                                    # ConfiguraÃ§Ãµes do banco
â”œâ”€â”€ docker-compose.yml                      # DefiniÃ§Ã£o do container PostgreSQL
â”œâ”€â”€ requirements.txt                        # DependÃªncias Python
â”‚
â”œâ”€â”€ bronze_extraction.py                    #  Camada Bronze - ExtraÃ§Ã£o
â”œâ”€â”€ transformations.py                #  Camada Silver - Limpeza 
â”œâ”€â”€ postgres_loader.py                         #  Camada Gold - Carregamento 
â”‚
â”œâ”€â”€ postgres_ddl.sql                         # Consultas SQL de valor
â”œâ”€â”€ README.md                               # Este arquivo
â”‚
â”œâ”€â”€ data/                                   # DiretÃ³rio de dados 
â”‚   â”œâ”€â”€ bronze/                                # Dados brutos em Parquet
â”‚   â”œâ”€â”€ silver/                             # Dados limpos em Parquet
â”‚   
```

---

##  Como Executar

### ExecuÃ§Ã£o Completa do Pipeline

```bash
# 1. Camada Bronze - ExtraÃ§Ã£o
python src/extraction.py

# 2. Camada Silver - TransformaÃ§Ã£o
python src/transformations.py

# 3. Camada Gold - Carregamento no PostgreSQL
python src/postgres_loader.py

```

### ExecuÃ§Ã£o das Consultas SQL

```bash
# Conectar ao PostgreSQL
docker exec -it ecommerce_postgres psql -U postgres -d ecommerce

# Dentro do psql, executar as consultas do arquivo sql_queries.sql
\i sql_queries.sql

# Ou executar consultas individuais:
SELECT * FROM customers LIMIT 5;
```


---

## Camadas de Dados

### ğŸ¥‰ Bronze Layer (Raw Data)

**Objetivo:** IngestÃ£o de dados brutos sem transformaÃ§Ã£o

**CaracterÃ­sticas:**
- Preserva dados originais exatamente como recebidos
- Formato: Parquet (compressÃ£o eficiente)
- Versionamento por timestamp
- Serve como fonte Ãºnica da verdade

**ValidaÃ§Ãµes:**
-  Arquivo existe e Ã© vÃ¡lido JSON
-  Estrutura bÃ¡sica do JSON Ã© vÃ¡lida
-  NÃ£o valida conteÃºdo dos campos

**SaÃ­da:** `data/bronze/{entity}.parquet`

---

###  Silver Layer (Cleaned Data)

**Objetivo:** Limpeza, normalizaÃ§Ã£o e validaÃ§Ã£o de qualidade

**TransformaÃ§Ãµes aplicadas:**

1. **Emails:**
   - ConversÃ£o para lowercase
   - RemoÃ§Ã£o de espaÃ§os (trim)
   - ValidaÃ§Ã£o de formato (`@` presente)

2. **Datas:**
   - ConversÃ£o para formato padrÃ£o ISO 8601 (YYYY-MM-DD)
   - Suporte a mÃºltiplos formatos de entrada:
     - `2024-01-15T14:32:00Z`
     - `2024-01-15`
     - `15/01/2024`
     - `15/01/2024 14:32:00`

3. **Valores MonetÃ¡rios:**
   - ConversÃ£o para tipo numÃ©rico (float/decimal)
   - RemoÃ§Ã£o de caracteres especiais
   - ValidaÃ§Ã£o de valores negativos


5. **Relacionamentos:**
   - VinculaÃ§Ã£o de orders com customers via email
   - ValidaÃ§Ã£o de integridade referencial

**CritÃ©rios de Descarte:**

| Entidade | CritÃ©rio de Descarte | Justificativa |
|----------|---------------------|---------------|
| **Customers** | Email invÃ¡lido ou vazio | Campo obrigatÃ³rio para identificaÃ§Ã£o |
| **Customers** | customer_id vazio | Chave primÃ¡ria obrigatÃ³ria |
| **Orders** | transaction_id vazio | Chave primÃ¡ria obrigatÃ³ria |
| **Orders** | amount invÃ¡lido/negativo | Valor de pedido deve ser positivo |
| **Orders** | status invÃ¡lido | Apenas: completed, pending, cancelled, refunded |
| **Orders** | customer_id nÃ£o encontrado | Integridade referencial |

**SaÃ­da:** `data/silver/{entity}.parquet`

---

### ğŸ¥‡Gold Layer (Business/Analytics)

**Objetivo:** Modelo dimensional otimizado para anÃ¡lise

**Modelo de Dados:**

```sql
customers
â”œâ”€â”€ customer_id (PK)
â”œâ”€â”€ name
â”œâ”€â”€ email (UNIQUE)
â”œâ”€â”€ phone
â”œâ”€â”€ registration_date
â”œâ”€â”€ country
â”œâ”€â”€ city
â””â”€â”€ created_at

orders
â”œâ”€â”€ transaction_id (PK)
â”œâ”€â”€ customer_id (FK â†’ customers)
â”œâ”€â”€ payment_method
â”œâ”€â”€ amount
â”œâ”€â”€ currency
â”œâ”€â”€ payment_date
â”œâ”€â”€ status
â””â”€â”€ created_at
```

**CaracterÃ­sticas:**
- Chaves primÃ¡rias e estrangeiras
- Ãndices para performance
- Constraints de integridade
- Suporta re-execuÃ§Ã£o sem duplicaÃ§Ã£o (UPSERT)

---

## ğŸ—„ï¸ Modelo de Dados

### Tabela: `customers`

| Coluna | Tipo | RestriÃ§Ãµes | DescriÃ§Ã£o |
|--------|------|-----------|-----------|
| customer_id | VARCHAR(20) | PRIMARY KEY | Identificador Ãºnico do cliente |
| name | VARCHAR(200) | - | Nome completo |
| email | VARCHAR(200) | UNIQUE, NOT NULL | Email (normalizado) |
| phone | VARCHAR(50) | - | Telefone de contato |
| registration_date | DATE | - | Data de cadastro |
| country | VARCHAR(100) | - | PaÃ­s (normalizado) |
| city | VARCHAR(100) | - | Cidade |
| created_at | TIMESTAMP | DEFAULT NOW() | Timestamp de inserÃ§Ã£o |

### Tabela: `orders`

| Coluna | Tipo | RestriÃ§Ãµes | DescriÃ§Ã£o |
|--------|------|-----------|-----------|
| transaction_id | VARCHAR(20) | PRIMARY KEY | Identificador Ãºnico da ordem |
| customer_id | VARCHAR(20) | FK, NOT NULL | ReferÃªncia ao cliente |
| payment_method | VARCHAR(50) | - | MÃ©todo de pagamento |
| amount | DECIMAL(10,2) | NOT NULL | Valor da ordem |
| currency | VARCHAR(10) | - | Moeda (MXN, ARS, BRL, etc.) |
| payment_date | DATE | - | Data do pagamento |
| status | VARCHAR(20) | NOT NULL | Status da ordem |
| created_at | TIMESTAMP | DEFAULT NOW() | Timestamp de inserÃ§Ã£o |

### Relacionamentos

```
customers (1) â”€â”€< (N) orders
   â†‘                    â”‚
   â””â”€â”€â”€ customer_id â”€â”€â”€â”€â”˜
```

**Cardinalidade:** Um cliente pode ter mÃºltiplos pedidos (1:N)

**Integridade Referencial:** 
- `ON DELETE CASCADE` â†’ Se um cliente for deletado, seus pedidos tambÃ©m sÃ£o
- Foreign Key garante que todo pedido tem um cliente vÃ¡lido

---

## ğŸ“Š Consultas SQL

### 1. Total de Vendas por Cliente

**Objetivo:** Identificar os clientes mais valiosos (VIP)

```sql
SELECT 
    c.customer_id,
    c.name,
    c.email,
    c.country,
    COUNT(o.transaction_id) AS total_orders,
    SUM(CASE WHEN o.status = 'completed' THEN o.amount ELSE 0 END) AS total_sales,
    ROUND(AVG(CASE WHEN o.status = 'completed' THEN o.amount END), 2) AS avg_order_value
FROM customers c
LEFT JOIN orders o ON c.customer_id = o.customer_id
GROUP BY c.customer_id, c.name, c.email, c.country
ORDER BY total_sales DESC;
```

---

### 2. NÃºmero de Pedidos por PaÃ­s

**Objetivo:** AnÃ¡lise geogrÃ¡fica de operaÃ§Ãµes

```sql
SELECT 
    c.country,
    COUNT(DISTINCT c.customer_id) AS total_customers,
    COUNT(o.transaction_id) AS total_orders,
    COUNT(CASE WHEN o.status = 'completed' THEN 1 END) AS completed_orders,
    SUM(CASE WHEN o.status = 'completed' THEN o.amount ELSE 0 END) AS total_revenue,
    ROUND(
        100.0 * COUNT(CASE WHEN o.status = 'completed' THEN 1 END) / 
        NULLIF(COUNT(o.transaction_id), 0), 
        2
    ) AS conversion_rate_pct
FROM customers c
LEFT JOIN orders o ON c.customer_id = o.customer_id
WHERE c.country IS NOT NULL
GROUP BY c.country
ORDER BY total_revenue DESC;
```
---

### 3. Ticket MÃ©dio

**Objetivo:** Entender valor mÃ©dio de compra

```sql
-- Ticket mÃ©dio geral
SELECT 
    ROUND(AVG(amount), 2) AS avg_ticket,
    ROUND(MIN(amount), 2) AS min_ticket,
    ROUND(MAX(amount), 2) AS max_ticket,
    COUNT(*) AS total_orders,
    SUM(amount) AS total_revenue
FROM orders
WHERE status = 'completed';

-- Ticket mÃ©dio por mÃ©todo de pagamento
SELECT 
    payment_method,
    COUNT(*) AS order_count,
    ROUND(AVG(amount), 2) AS avg_ticket,
    SUM(amount) AS total_revenue
FROM orders
WHERE status = 'completed'
GROUP BY payment_method
ORDER BY avg_ticket DESC;
```

---

##  DecisÃµes TÃ©cnicas

### 1. Por que Pandas em vez de PySpark?

**DecisÃ£o:** Usar Pandas

**Justificativa:**
- Volume de dados Ã© pequeno (< 1 GB)
- Simplicidade e curva de aprendizado
- Biblioteca madura e bem documentada
- Suficiente para o escopo do projeto

**Quando migrar para PySpark:**
- Dados > 10 GB
- Necessidade de processamento distribuÃ­do
- OperaÃ§Ãµes complexas de window functions

---

### 2. Por que Parquet em vez de CSV?

**DecisÃ£o:** Usar Parquet nas camadas Bronze e Silver

**Justificativa:**
- Formato colunar â†’ melhor compressÃ£o (60-80% menor que CSV)
- Preserva tipos de dados
- Leitura mais rÃ¡pida (especialmente com filtros)
- Schema embedding


---

### 3. Por que SQLAlchemy em vez de psycopg2 puro?

**DecisÃ£o:** Usar SQLAlchemy

**Justificativa:**
- AbstraÃ§Ã£o de banco (fÃ¡cil trocar MySQL, PostgreSQL, etc.)
- ORM opcional (podemos usar SQL puro tambÃ©m)
- Melhor tratamento de transaÃ§Ãµes
- PadrÃ£o da indÃºstria

---

### 4. Por que arquitetura Medallion?

**DecisÃ£o:** Bronze â†’ Silver â†’ Gold

**Justificativa:**
- **Rastreabilidade:** Sempre podemos voltar aos dados brutos
- **Flexibilidade:** Regras de limpeza podem mudar
- **Performance:** Processar incrementalmente
- **GovernanÃ§a:** Camadas claras de responsabilidade

---

### 5. IdempotÃªncia: Como garantir?

**Problema:** Pipeline pode ser executado mÃºltiplas vezes

**SoluÃ§Ãµes implementadas:**

```sql
-- 1. TRUNCATE + INSERT (simples, mas perde histÃ³rico)
TRUNCATE TABLE customers;
INSERT INTO customers VALUES (...);


---

##  Logs e Monitoramento

### NÃ­veis de Log

```python
logging.DEBUG    # Detalhes tÃ©cnicos para debugging
logging.INFO     # Progresso normal do pipeline
logging.WARNING  # Alertas (ex: dados faltantes, mas nÃ£o crÃ­tico)
logging.ERROR    # Erros que impedem parte do processo
logging.CRITICAL # Falhas catastrÃ³ficas
```


